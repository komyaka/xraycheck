# Speedtest конфигов из configs/available и configs/white-list_available
# configs/available_st, configs/available_st(top100), configs/white-list_available_st, configs/white-list_available_st(top100).
# Запускается: после Daily VLESS check (Docker / whitelist), по расписанию каждые 2 ч, вручную (workflow_dispatch).
# Параметры speedtest - из .env (см. комментарии в шагах).

name: Speedtest available

on:
  workflow_run:
    workflows: ["Daily VLESS check (Docker / whitelist)"]
    types: [completed]
    branches: [main]
  schedule:
    - cron: '0 */2 * * *'
  workflow_dispatch:

env:
  MAX_WORKERS: 400
  BASE_PORT: 20000
  XRAY_STARTUP_WAIT: 1.8
  XRAY_STARTUP_POLL_INTERVAL: 0.2
  SPEED_TEST_ENABLED: 'true'
  SPEED_TEST_TIMEOUT: 2
  SPEED_TEST_MODE: full
  SPEED_TEST_METRIC: latency
  SPEED_TEST_OUTPUT: separate_file
  SPEED_TEST_REQUESTS: 5
  SPEED_TEST_URL: https://www.gstatic.com/generate_204
  SPEED_TEST_WORKERS: 400
  SPEED_TEST_DOWNLOAD_TIMEOUT: 30
  SPEED_TEST_DOWNLOAD_URL_SMALL: https://speed.cloudflare.com/__down?bytes=250000
  SPEED_TEST_DOWNLOAD_URL_MEDIUM: https://speed.cloudflare.com/__down?bytes=1000000
  MIN_SPEED_THRESHOLD_MBPS: 1
  SPEED_TEST_DEBUG: 'false'
  OUTPUT_DIR: configs
  VERIFY_HTTPS_SSL: 'false'

jobs:
  speedtest-and-publish:
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'schedule' || github.event.workflow_run.conclusion == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 120
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Ensure configs/available and configs/white-list_available exist
        run: |
          for f in configs/available configs/white-list_available; do
            if [ ! -f "$f" ]; then
              echo "::error::$f not found. Run Daily VLESS check first."
              exit 1
            fi
            if [ ! -s "$f" ]; then
              echo "::error::$f is empty."
              exit 1
            fi
            echo "$f: $(wc -l < "$f") lines"
          done

      - name: Run speedtest on configs/available
        run: python speedtest_checker.py configs/available
        env:
          MAX_WORKERS: ${{ env.MAX_WORKERS }}
          BASE_PORT: ${{ env.BASE_PORT }}
          XRAY_STARTUP_WAIT: ${{ env.XRAY_STARTUP_WAIT }}
          XRAY_STARTUP_POLL_INTERVAL: ${{ env.XRAY_STARTUP_POLL_INTERVAL }}
          VERIFY_HTTPS_SSL: ${{ env.VERIFY_HTTPS_SSL }}
          SPEED_TEST_ENABLED: ${{ env.SPEED_TEST_ENABLED }}
          SPEED_TEST_TIMEOUT: ${{ env.SPEED_TEST_TIMEOUT }}
          SPEED_TEST_MODE: ${{ env.SPEED_TEST_MODE }}
          SPEED_TEST_METRIC: ${{ env.SPEED_TEST_METRIC }}
          SPEED_TEST_OUTPUT: ${{ env.SPEED_TEST_OUTPUT }}
          SPEED_TEST_REQUESTS: ${{ env.SPEED_TEST_REQUESTS }}
          SPEED_TEST_URL: ${{ env.SPEED_TEST_URL }}
          SPEED_TEST_WORKERS: ${{ env.SPEED_TEST_WORKERS }}
          SPEED_TEST_DOWNLOAD_TIMEOUT: ${{ env.SPEED_TEST_DOWNLOAD_TIMEOUT }}
          SPEED_TEST_DOWNLOAD_URL_SMALL: ${{ env.SPEED_TEST_DOWNLOAD_URL_SMALL }}
          SPEED_TEST_DOWNLOAD_URL_MEDIUM: ${{ env.SPEED_TEST_DOWNLOAD_URL_MEDIUM }}
          MIN_SPEED_THRESHOLD_MBPS: ${{ env.MIN_SPEED_THRESHOLD_MBPS }}
          SPEED_TEST_DEBUG: ${{ env.SPEED_TEST_DEBUG }}
          OUTPUT_DIR: ${{ env.OUTPUT_DIR }}

      - name: Run speedtest on configs/white-list_available
        run: python speedtest_checker.py configs/white-list_available
        env:
          MAX_WORKERS: ${{ env.MAX_WORKERS }}
          BASE_PORT: ${{ env.BASE_PORT }}
          XRAY_STARTUP_WAIT: ${{ env.XRAY_STARTUP_WAIT }}
          XRAY_STARTUP_POLL_INTERVAL: ${{ env.XRAY_STARTUP_POLL_INTERVAL }}
          VERIFY_HTTPS_SSL: ${{ env.VERIFY_HTTPS_SSL }}
          SPEED_TEST_ENABLED: ${{ env.SPEED_TEST_ENABLED }}
          SPEED_TEST_TIMEOUT: ${{ env.SPEED_TEST_TIMEOUT }}
          SPEED_TEST_MODE: ${{ env.SPEED_TEST_MODE }}
          SPEED_TEST_METRIC: ${{ env.SPEED_TEST_METRIC }}
          SPEED_TEST_OUTPUT: ${{ env.SPEED_TEST_OUTPUT }}
          SPEED_TEST_REQUESTS: ${{ env.SPEED_TEST_REQUESTS }}
          SPEED_TEST_URL: ${{ env.SPEED_TEST_URL }}
          SPEED_TEST_WORKERS: ${{ env.SPEED_TEST_WORKERS }}
          SPEED_TEST_DOWNLOAD_TIMEOUT: ${{ env.SPEED_TEST_DOWNLOAD_TIMEOUT }}
          SPEED_TEST_DOWNLOAD_URL_SMALL: ${{ env.SPEED_TEST_DOWNLOAD_URL_SMALL }}
          SPEED_TEST_DOWNLOAD_URL_MEDIUM: ${{ env.SPEED_TEST_DOWNLOAD_URL_MEDIUM }}
          MIN_SPEED_THRESHOLD_MBPS: ${{ env.MIN_SPEED_THRESHOLD_MBPS }}
          SPEED_TEST_DEBUG: ${{ env.SPEED_TEST_DEBUG }}
          OUTPUT_DIR: ${{ env.OUTPUT_DIR }}

      - name: Verify output and update last-updated.json
        run: |
          if [ ! -f "configs/available_st" ] && [ ! -f "configs/white-list_available_st" ]; then
            echo "::warning::Neither configs/available_st nor configs/white-list_available_st created (no successful results?), skip push"
            exit 0
          fi
          for base in available_st "white-list_available_st"; do
            if [ -f "configs/$base" ] && [ ! -f "configs/${base}(top100)" ]; then
              head -n 100 "configs/$base" > "configs/${base}(top100)"
            fi
          done
          NOW=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          C_AV=$(wc -l < configs/available_st 2>/dev/null || echo 0)
          C_AV100=$(wc -l < "configs/available_st(top100)" 2>/dev/null || echo 0)
          C_WL=$(wc -l < configs/white-list_available_st 2>/dev/null || echo 0)
          C_WL100=$(wc -l < "configs/white-list_available_st(top100)" 2>/dev/null || echo 0)
          OLD=$(cat configs/last-updated.json 2>/dev/null || echo '{}')
          echo "$OLD" | jq -c --arg t "$NOW" \
            --argjson c_av "$C_AV" --argjson c_av100 "$C_AV100" \
            --argjson c_wl "$C_WL" --argjson c_wl100 "$C_WL100" \
            '.["configs/available_st"] = {updated: $t, count: $c_av} |
             .["configs/available_st(top100)"] = {updated: $t, count: $c_av100} |
             .["configs/white-list_available_st"] = {updated: $t, count: $c_wl} |
             .["configs/white-list_available_st(top100)"] = {updated: $t, count: $c_wl100}' \
            > configs/last-updated.json
          echo "Output:"
          ls -la configs/available_st "configs/available_st(top100)" configs/white-list_available_st "configs/white-list_available_st(top100)" 2>/dev/null || true

      - name: Commit and push speedtest results
        run: |
          if [ ! -f "configs/available_st" ] && [ ! -f "configs/white-list_available_st" ]; then
            echo "Nothing to commit (no successful speedtest results)."
            exit 0
          fi
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          for f in configs/available_st "configs/available_st(top100)" configs/white-list_available_st "configs/white-list_available_st(top100)" configs/last-updated.json; do
            [ -f "$f" ] && git add "$f"
          done
          if ! git diff --cached --quiet; then
            git commit -m "update available_st and white-list_available_st (speedtest) [automated]"
            git pull --rebase origin "${{ github.ref_name }}"
            git push
          else
            echo "Speedtest results unchanged, skip push"
          fi
